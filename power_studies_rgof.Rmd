---
title:  Simulation Studies For 1G Goodness-of-Fit Methods
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error=TRUE)
library(Rgof)
set.seed(1111)

case.studies = c(
  "uniform.linear", "uniform.quadratic", "uniform.bump", "uniform.spike",
  "beta", "beta2",
   "normal.shift", "normal.stretch", "normal.outlier1", "normal.outlier2", "normal.t", 
   "exponential.gamma", "exponential.weibull", "exponential.bump", "trunc.exponential.linear", 
   "normal.t.est", "exponential.weibull.est", 
  "trunc.exponential.linear.est", "exponential.gamma.est",
  "normal.cauchy.est"
  )
case.studies.cont = paste0(case.studies,".cont")
case.studies.disc = paste0(case.studies,".disc")
whichTOrerun="uniform.linear.cont"
```


## Routines

To study the relative powers of the methods we proceed as follows: in each case study one data set is drawn from a fixed distribution. The other data set comes from a distribution with a free parameter. This parameter is chosen in such a way that for small (large) values the null hypothesis is true (or almost so) and the power is the nominal type I error of $5\%$. Then for increasing (decreasing) values the powers increase to eventually $100\%$. Therefore there is one value of the parameter where for the first time at least one method has a power exceeding $100p\%$. The routine *find.par* finds this value of the parameter and returns the respective powers.

```{r}
find.par=function(pwr, power=0.8) {
   for(i in 1:nrow(pwr)) {
       if(max(pwr[i, ])>power) break
   }
   pwr[i, ]
}
```

The routine **ggcurve** draws the theoretical densities in the case studies using the parameter values where the two differ the most.

```{r}
ggcurve <- function (f, g, ymax, xrange=c(0, 1), npoints = 250) 
{
    x <- seq(xrange[1], xrange[2], length = npoints)
    y <- f(x)
    dta <- data.frame(x = c(x, x), 
                      y = c(f(x), g(x)),
                      D=rep(c("f","g"), each=npoints)
           )
    if(missing(ymax)) ymax=1.2*max(dta$y)
    ggplot(aes(x, y, colour=D), data = dta)+
      geom_line(size = 1.5) + 
      lims(y=c(0, ymax)) + 
      theme ( legend.position = "none")  
}
```

The routine **multiple.graphs** draws a several ggplot graphs together.

```{r}
multiple.graphs = function (plt1, plt2, plt3, plt4, Horizontal = TRUE, titles) 
{
     require(ggplot2)
     require(grid)
     if(!missing(titles)) {
          plt1<-plt1+ggtitle(titles[1])
          plt2<-plt2+ggtitle(titles[2])
          if(!missing(plt3))          
               plt3<-plt3+ggtitle(titles[3])
          if(!missing(plt4))               
               plt4<-plt4+ggtitle(titles[4])          
     }     
     if(missing(plt3)) {
        if(Horizontal)
          pushViewport(viewport(layout = grid.layout(1, 2)))
        else
          pushViewport(viewport(layout = grid.layout(2, 1)))  
     }     
     else
        pushViewport(viewport(layout = grid.layout(2, 2)))     
     print(plt1, vp = viewport(layout.pos.row = 1, layout.pos.col = 1))
     if(Horizontal)
        print(plt2, vp = viewport(layout.pos.row = 1, layout.pos.col = 2))
     else
        print(plt2, vp = viewport(layout.pos.row = 2, layout.pos.col = 1))   
     if(!missing(plt3))
        print(plt3, vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) 
     if(!missing(plt4))
        print(plt4, vp = viewport(layout.pos.row = 2, layout.pos.col = 2)) 
}    

```


The routine **comp.power** finds the method(s) with the highest mean power for both the continuous and the discrete data and draws them together. This allows us to assess the effect of binning the data on the power of the tests.

```{r}
comp.power=function(cont, disc) {
  m=apply(cont, 2, mean)
  cm=colnames(cont)[m==max(m)][1] 
  m=apply(disc, 2, mean)
  dm=colnames(disc)[m==max(m)][1]   
  dta=data.frame(
    x=c(as.numeric(rownames(cont)), as.numeric(rownames(disc))),
    y=c(cont[, cm], disc[,dm]),
    Data=rep(c(paste("Continuous - ",cm), 
               paste("Discrete - ", dm)), 
             c(nrow(cont), nrow(disc)))
  )  
  ggplot2::ggplot(data=dta, aes(x,y,colour=Data))+
    ggplot2::geom_smooth(formula = y ~ x, method = "loess", span=0.25,se=FALSE)
}
```

## Case Study 1: Uniform [0,1] - Linear

The density of the linear model is given by $f(x)=2sx+1-s;0<x<1$, so the parameter is the slope of the line.

**Example Densities**

```{r}
ggcurve(dunif, function(x) 2*0.4*x+1-0.4, 2)
```

**Continuous**

```{r uniform.linear.cont}
pnull = function(x) punif(x)
qnull = function(x) qunif(x)
rnull = function() runif(500)
ralt = function(slope) {
  if(slope==0) y=runif(500)
    else y=(slope-1+sqrt((1-slope)^2+4*slope* runif(500)))/2/slope
}    
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
        param_alt=seq(0, 0.5, length=25), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_80=rbind("1: Uniform - Linear" = find.par(pwr_cont))
par_cont_05=rbind("1: Uniform - Linear" = pwr_cont[1, ])
```

**Discrete**

```{r uniform.linear.disc}
vals=1:50/51
pnull = function() (1:50)/50
rnull = function() c(rmultinom(1, 500, rep(1/50,50)))
ralt = function(slope) {
    if(slope==0) p=rep(1/50, 50)
    else p=diff(slope * (0:50/50)^2 + (1 - slope) * 0:50/50)  
  c(rmultinom(1, 500, p))
}  

which = "uniform.linear.disc"
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
            param_alt=seq(0, 0.5, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```


```{r}
multiple.graphs(
  plot_power(pwr_cont, "slope"),
  plot_power(pwr_disc, "slope"))
par_disc_05=rbind("1: Uniform - Linear" = pwr_disc[1, ])
par_disc_80=rbind("1: Uniform - Linear" = find.par(pwr_disc,0.8))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 2: Uniform [0,1]  - Quadratic

The density of the quadratic model is given by $f(x) =\frac{1+a(x-0.5)^2}{1+a/12} ;0<x<1$. So

**Example Densities**

```{r}
ggcurve(dunif, function(x) (1+5*(x-0.5)^2)/(1+5/12), 2)
```

The following routine uses accept-reject to generate data from this distribution.

**Continuous**

```{r uniform.quadratic.cont}
pnull = function(x) punif(x)
qnull = function(x) qunif(x)
rnull = function() runif(500)
ralt=function(a) {
  n = 500
  if(a==0) return(runif(n))
  y=rep(0,n)
  for(i in 1:n) {
    repeat {
      x=runif(1)
      if(runif(1)<(1+a*(x-0.5)^2)/(1+a/4)) {
        y[i]=x
        break
      }
    } 
  }
  y
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
              param_alt=seq(0, 6, length=25), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```


```{r}
par_cont_80=rbind(par_cont_80, "2: Uniform - Quadratic"=find.par(pwr_cont))
par_cont_05=rbind(par_cont_05, "2: Uniform - Quadratic"=pwr_cont[1, ])
```

**Discrete**

```{r uniform.quadratic.disc}
vals=1:50/51
pnull = function() (1:50)/50
rnull = function() c(rmultinom(1, 500, rep(1/50,50)))
ralt = function(a) {
    if(a==0) p=rep(1/50, 50)
    else p=diff( (24*0:50/50+a+8*a*((0:50/50)-1/2)^3)/(24+2*a) )
  c(rmultinom(1, 500, p))
}  

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
                      param_alt=seq(0, 6, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
multiple.graphs(
  plot_power(pwr_cont, "a"),
  plot_power(pwr_disc, "a"))
par_disc_80=rbind(par_disc_80, "2: Uniform - Quadratic"= find.par(pwr_disc,0.8))
par_disc_05=rbind(par_disc_05, "2: Uniform - Quadratic" = pwr_disc[1, ])
```


**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 3: Uniform - Uniform with Bump

**Example Densities**

```{r}
ggcurve(dunif, function(x) (500+200*dnorm(x,0.5,0.05))/700, 3)
```


**Continuous**

```{r uniform.bump.cont}
pnull = function(x) punif(x)
qnull = function(x) qunif(x)
rnull = function() runif(500)
ralt=function(n) c(runif(500-n), rnorm(n, 0.5, 0.05))

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
                param_alt=round(seq(0, 150, length=25)), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```


```{r}
par_cont_80=rbind(par_cont_80, "3: Uniform - Uniform+Bump"=find.par(pwr_cont))
par_cont_05=rbind(par_cont_05, "3: Uniform - Uniform+Bump"=pwr_cont[1, ])
```

**Discrete**

```{r uniform.bump.disc}
vals=1:50/51
pnull = function()(1:50)/50
rnull = function() c(rmultinom(1, 500, rep(1/50,50)))
ralt = function(n) {
  bins = 0:50/50
  p=diff( ( (500-n)*punif(bins)+n*pnorm(bins, 0.5, 0.05))/500)
  c(rmultinom(1, 500, p))
}  

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
            param_alt=round(seq(0, 150, length=25)))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
multiple.graphs(
  plot_power(pwr_cont, "n"),
  plot_power(pwr_disc, "n"))
par_disc_80=rbind(par_disc_80, "3: Uniform - Uniform+Bump"= find.par(pwr_disc,0.8))
par_disc_05=rbind(par_disc_05, "3: Uniform - Uniform+Bump" = pwr_disc[1, ])
```


**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 4:  Uniform - Spikes


**Example Densities**

```{r}
f=function(x,a=0.2) {
  y=x*0
  y[x>=0] = 2*a*x+1-a/4
  y[x>0.25] = 2*a*(x[x>0.25]-0.25)+1-a/4
  y[x>0.5] = 2*a*(x[x>0.5]-0.5)+1-a/4
  y[x>0.75] = 2*a*(x[x>0.75]-0.75)+1-a/4
  y
}
ggcurve(dunif, f)
```


**Continuous**

```{r uniform.spike.cont}
pnull = function(x) punif(x)
qnull = function(x) qunif(x)
rnull = function() runif(500)
ralt=function(b) {
  if(b==0) return(rnull())
  y=(b-1+sqrt((1-b)^2+4*b* runif(500)))/2/b
  z=sample( (0:3)/4, 500, replace=TRUE)
  z+y/4      
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt,  
                param_alt=round(seq(0, 1.5,length=25), 3), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_80=rbind(par_cont_80, "4: Uniform - Spikes"=find.par(pwr_cont))
par_cont_05=rbind(par_cont_05, "4: Uniform - Spikes"=pwr_cont[1, ])
```

**Discrete**

```{r uniform.spike.disc}
vals=1:50/51
pnull = function() (1:50)/50
rnull = function() c(rmultinom(1, 500, rep(1/50,50)))
ralt = function(b) {
  if(b==0) return(rnull())
  y=(b-1+sqrt((1-b)^2+4*b* runif(500)))/2/b
  z=sample( (0:3)/4, 500, replace=TRUE)
  hist(z+y/4, 0:50/50, plot=FALSE)$counts      
}  

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
          param_alt=round(seq(0, 1.5,length=25), 3))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
multiple.graphs(
  plot_power(pwr_cont, "n"),
  plot_power(pwr_disc, "n"))
par_disc_80=rbind(par_disc_80, "4: Uniform - Spikes"= find.par(pwr_disc,0.8))
par_disc_05=rbind(par_disc_05, "4: Uniform - Spikes" = pwr_disc[1, ])
```


**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 5: Beta(2,2) - Beta(b,b)

**Example Densities**

```{r}
ggcurve(function(x) dbeta(x,2,2), function(x) dbeta(x,4,4))
```


**Continuous**

```{r beta.cont}
pnull = function(x) pbeta(x, 2, 2)
qnull = function(x) qbeta(x, 2, 2)
rnull = function() rbeta(500, 2, 2)
ralt = function(b=2) rbeta(500, b, b)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
              param_alt=round(seq(2, 4,length=25), 3),  Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "5: Beta(2,2) - Beta(a,a)" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "5: Beta(2,2) - Beta(a,a)" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r beta.disc}
bins=0:50/50
vals=1:50/51
pnull = function() {
  bins=0:50/50
  pbeta(bins[-1], 2, 2)
}  
rnull=function() {
  bins=0:50/50
  p=diff(pbeta(bins, 2, 2))
  c(rmultinom(1, 500, p))
}
ralt=function(b=2) {
  bins=0:50/50
  p=diff(pbeta(bins, b, b))
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
            param_alt=seq(2, 4, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "5: Beta(2,2) - Beta(a,a)" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "5: Beta(2,2) - Beta(a,a)" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "a"), 
                plot_power(pwr_disc, "a"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 6: Beta(2,2) - Beta(2,b)

**Example Densities**

```{r}
ggcurve(function(x) dbeta(x,2,2), function(x) dbeta(x,2,4))
```


**Continuous**

```{r beta2.cont}
pnull = function(x) pbeta(x, 2, 2)
qnull = function(x) qbeta(x, 2, 2)
rnull = function() rbeta(500, 2, 2)
ralt = function(b=2) rbeta(500, 2, b)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
        param_alt=round(seq(2, 3,length=25), 3), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "6: Beta(2,2) - Beta(2,a)" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "6: Beta(2,2) - Beta(2,a)" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r beta2.disc}
bins=0:50/50
vals=1:50/51
pnull = function() {
  bins=0:50/50
  pbeta(bins[-1], 2, 2)
}
rnull=function() {
  bins=0:50/50
  p=diff(pbeta(bins, 2, 2))
  c(rmultinom(1, 500, p))
}
ralt=function(b=2) {
  bins=0:50/50
  p=diff(pbeta(bins, 2, b))
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
            param_alt=seq(2, 3, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "6: Beta(2,2) - Beta(2,a)" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "6: Beta(2,2) - Beta(2,a)" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "a"), 
                plot_power(pwr_disc, "a"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 7:  Normal - Shift

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), function(x) dnorm(x, 0.4), xrange=c(-3,3))
```


**Continuous**

```{r normal.shift.cont}
pnull = function(x) pnorm(x)
qnull = function(x) qnorm(x)
rnull = function() rnorm(500)
ralt = function(mu=0) rnorm(500, mu)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
          param_alt=seq(0, 0.4,length=25))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "7: Normal - Shift" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "7: Normal - Shift" = find.par(pwr_cont,0.8))
```


**Discrete**

```{r normal.shift.disc}
bins=seq(-2.5, 2.5, length=49)
vals=c(-2.8, (bins[-1]+bins[-49])/2, 2.8)

pnull = function() {
  bins=seq(-2.5, 2.5, length=49)
  c(pnorm(bins), 1)
}

rnull=function() {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pnorm(bins), 1))
  c(rmultinom(1, 500, p))
}
ralt=function(mu=0) {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pnorm(bins, mu), 1))
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
            param_alt=seq(0, 0.4, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "7: Normal - Shift" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "7: Normal - Shift" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "mu"), 
                plot_power(pwr_disc, "mu"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 8:  Normal - Stretch

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), function(x) dnorm(x, 0, 2), xrange=c(-5,5))
```


**Continuous**

```{r normal.stretch.cont}
pnull = function(x) pnorm(x)
qnull = function(x) qnorm(x)
rnull = function() rnorm(500)
ralt = function(s=1) rnorm(500, 0, s)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
              param_alt=seq(1, 1.4,length=25))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "8: Normal  - Stretch" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "8: Normal  - Stretch" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r normal.stretch.disc}
bins=seq(-2.5, 2.5, length=49)
vals=c(-2.8, (bins[-1]+bins[-49])/2, 2.8)

pnull = function() {
  bins=seq(-2.5, 2.5, length=49)
  c(pnorm(bins), 1)
}

rnull=function() {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pnorm(bins), 1))
  c(rmultinom(1, 500, p))
}
ralt=function(s=1) {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pnorm(bins, 0, s), 1))
  c(rmultinom(1, 500, p))
}
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
          param_alt=seq(1, 1.4, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "8: Normal  - Stretch" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "8: Normal  - Stretch" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "a"), 
                plot_power(pwr_disc, "a"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 9:  Normal - t

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), function(x) dt(x, 2), xrange=c(-5,5))
```


**Continuous**

```{r normal.t.cont}
pnull = function(x) pnorm(x)
qnull = function(x) qnorm(x)
rnull = function() rnorm(500)
ralt = function(df=1) rt(500, df)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, param_alt=2*1:25)
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
a=nrow(pwr_cont)
par_cont_80=rbind(par_cont_80, "9: Normal  - t" = find.par(pwr_cont[a:1,],0.8))
```

**Note** no check for type I error as null hypothesis is always false.

**Discrete**

```{r normal.t.disc}
bins=seq(-2.5, 2.5, length=49)
vals=c(-2.8, (bins[-1]+bins[-49])/2, 2.8)

pnull = function() {
  bins=seq(-2.5, 2.5, length=49)
  c(pnorm(bins), 1)
}

rnull=function() {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pnorm(bins), 1))
  c(rmultinom(1, 500, p))
}
ralt=function(df=1) {
  bins=seq(-2.5, 2.5, length=49) 
  p=diff(c(0, pt(bins, df), 1))
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
                param_alt=2*1:25)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
a=nrow(pwr_disc)
par_disc_80=rbind(par_disc_80, "9: Normal  - t" = find.par(pwr_disc[a:1,],0.8))
multiple.graphs(plot_power(pwr_cont, "df"), 
                plot_power(pwr_disc, "df"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 10: Normal - Normal with Asymmetric Outliers

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), function(x) (500*dnorm(x)+49*dnorm(x,5))/549, xrange=c(-3,8))
```



**Continuous**

```{r normal.outlier1.cont}
pnull = function(x) pnorm(x)
qnull = function(x) qnorm(x)
rnull = function() rnorm(500)
ralt = function(n=0) c(rnorm(500-2*n), runif(2*n, 2, 3))

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, param_alt=0:24)
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "10: Normal  - Outliers large" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "10: Normal  - Outliers large" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r normal.outlier1.disc}
bins=seq(-3, 3, length=49)
vals=c(-3.4, (bins[-1]+bins[-49])/2, 3.4)

pnull = function() {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  pnorm(bins[-1])
}

rnull=function() {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  hist(rnorm(500), bins, plot = FALSE)$counts
}
  
ralt=function(n=0) {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  hist(c(rnorm(500-2*n), runif(2*n, 2, 3)), bins, plot = FALSE)$counts
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
                          param_alt=0:24)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "10: Normal  - Outliers large" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "10: Normal  - Outliers large" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "n"), 
                plot_power(pwr_disc, "n"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 11: Normal - Normal with Symmetric Outliers

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), 
        function(x) (500*dnorm(x)+24*dunif(x,-5,-3)+24*dunif(x,3,5))/548,
        xrange=c(-6,6))
```



**Continuous**

```{r normal.outlier2.cont}
pnull = function(x) pnorm(x)
qnull = function(x) qnorm(x)
rnull = function() rnorm(500)
ralt = function(n=0) c(rnorm(500-2*n), runif(n, -3, -2), runif(n, 2, 3))

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, param_alt=0:24)
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "11: Normal  - Outliers" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "11: Normal  - Outliers" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r normal.outlier2.disc}
bins=seq(-3, 3, length=49)
vals=c(-3.4, (bins[-1]+bins[-49])/2, 3.4)

pnull = function() {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  pnorm(bins[-1])
}

rnull=function() {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  hist(rnorm(500), bins, plot = FALSE)$counts
}
  
ralt=function(n=0) {
  bins=c(-Inf, seq(-3, 3, length=49), Inf)
  hist(c(rnorm(500-2*n), runif(n, -3, -2), runif(n, 2, 3)), bins, plot = FALSE)$counts
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, param_alt=0:24)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "11: Normal  - Outliers" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "11: Normal  - Outliers" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "n"), 
                plot_power(pwr_disc, "n"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 12: Exponential  -  Gamma

```{r}
ggcurve(function(x) dexp(x,1), 
        function(x) dgamma(x, 1, 1.5),
        xrange=c(0,6))
```


**Continuous**

```{r exponential.gamma.cont}
pnull = function(x) pexp(x, 1)
qnull = function(x) qexp(x, 1)
rnull = function() rexp(500, 1)
ralt = function(b=1) rgamma(500, 1, b)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
        param_alt=seq(1, 1.3, length=25), Range=c(0,Inf))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "12: Exponential - Gamma" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "12: Exponential - Gamma" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r exponential.gamma.disc}
bins = seq(0, 4, length=50)
vals = c((bins[-1]+bins[-50])/2, 5)

pnull = function() {
  bins = seq(0, 4, length=50)
  pexp(c(bins[-1], Inf), 1)
}  

rnull=function() {
  bins = seq(0, 4, length=50)
  p=diff(pexp(c(bins, Inf), 1))  
  c(rmultinom(1, 500, p))
}

ralt=function(b=1) {
  bins = seq(0, 4, length=50)
  p=diff(pgamma(c(bins, Inf),  1, b))  
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
              param_alt=seq(1, 1.3, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "12: Exponential - Gamma" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "12: Exponential - Gamma" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```


## Case Study 13: Exponential  -  Weibull

```{r}
ggcurve(function(x) dexp(x,1), 
        function(x) dweibull(x, 1, 1.5),
        xrange=c(0,6))
```

**Continuous**

```{r exponential.weibull.cont}
pnull = function(x) pexp(x, 1)
qnull = function(x) qexp(x, 1)
rnull = function() rexp(500, 1)
ralt = function(b=1) rweibull(500, 1, b)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
      param_alt=seq(1, 1.5, length=25), Range=c(0,Inf))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "13: Exponential - Weibull" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "13: Exponential - Weibull" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r exponential.weibull.disc}
bins = seq(0, 4, length=51)
vals = (bins[-1]+bins[-51])/2
pnull = function() {
  bins = seq(0, 4, length=50)
  pexp(c(bins[-1], Inf), 1)
}  
rnull=function() {
  bins = seq(0, 4, length=50)
  p=diff(pexp(c(bins, Inf), 1))  
  c(rmultinom(1, 500, p))
}
ralt=function(b=1) {
  bins = seq(0, 4, length=50)
  p=diff(pweibull(c(bins, Inf),  1, b))  
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
              param_alt=seq(1, 1.5, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "13: Exponential - Weibull" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "13: Exponential - Weibull" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 14: Exponential - Exponential with Bump

```{r}
ggcurve(function(x) dexp(x,1), 
        function(x) (250*dexp(x,1)+75*dnorm(x,0.5,0.05))/325,
        xrange=c(0,3))
```

**Continuous**

```{r exponential.bump.cont}
pnull = function(x) pexp(x, 1)
qnull = function(x) qexp(x, 1)
rnull = function() rexp(500, 1)
ralt = function(n=0) c(rexp(500-n, 1), rnorm(n, 0.5, 0.05))

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
                param_alt=3*0:24, Range=c(0,Inf))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "14: Exponential - Bump" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "14: Exponential - Bump" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r exponential.bump.disc}
bins = seq(0, 4, length=51)
vals = (bins[-1]+bins[-51])/2
pnull = function() {
  bins = seq(0, 4, length=50)
  pexp(c(bins[-1], Inf), 1)
}  
rnull=function() {
  bins = seq(0, 4, length=50)
  p=diff(pexp(c(bins, Inf), 1))  
  c(rmultinom(1, 500, p))
}
ralt=function(n=0) {
  bins = c(seq(0, 4, length=50), Inf)
  p=diff( ((500-n)*pexp(bins, 1)+n*pnorm(bins, 0.5, 0.05))/500 )
  c(rmultinom(1, 500, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, param_alt=3*0:24)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "14: Exponential - Bump" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "14: Exponential - Bump" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```


## Case Study 15: Truncated Exponential  -  Linear

```{r}
ggcurve(function(x) dexp(x, 1)/diff(pexp(c(0, 1), 1)), 
        function(x) 2*(-0.4)*x+1-(-0.4))
```


**Continuous**

```{r trunc.exponential.linear.cont}
pnull = function(x) (1-exp(-x))/(1-exp(-1))
qnull = function(x) -log(1 - x*(1-exp(-1)))
rnull = function() {
    x <- NULL
    repeat {
        x = c(x, rexp(500, 1))
        x = x[x < 1]
        if (length(x) > 5000) 
            break
    }
    x[1:500]
}
ralt = function(slope) {
  if(slope==0) y=runif(500)
    else y=(slope-1+sqrt((1-slope)^2+4*slope* runif(500)))/2/slope
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt,    
        param_alt=seq(-0.5, -1, length=25), Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_80=rbind(par_cont_80, "15: Truncated Exponential - Linear" = find.par(pwr_cont,0.8))
```

**Note** no check for type I error as null hypothesis is always false.

**Discrete**

```{r trunc.exponential.linear.disc}
bins=0:50/50
vals=(bins[-1]+bins[-51])/2

pnull = function() {
  bins=1:50/50
  (1-exp(-bins))/(1-exp(-1))
}
rnull=function() {
  bins=0:50/50
  p=diff((1-exp(-bins))/(1-exp(-1)))
  c(rmultinom(1, 1000, p))
}
ralt = function(slope) {
    if(slope==0) p=rep(1/50, 50)
    else p=diff(slope * (0:50/50)^2 + (1 - slope) * 0:50/50)  
  c(rmultinom(1, 1000, p))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
                param_alt=seq(-0.5, -1, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_80=rbind(par_disc_80, "15: Truncated Exponential - Linear" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "slope"), 
                plot_power(pwr_disc, "slope"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```


## Case Study 16:  Normal - t, Estimated

**Example Densities**

```{r}
ggcurve(function(x) dnorm(x), function(x) dt(x, 2), xrange=c(-5,5))
```


**Continuous**

```{r normal.t.est.cont}
pnull = function(x, p=c(0,1)) pnorm(x, p[1], p[2])
qnull = function(x, p=c(0,1)) qnorm(x, p[1], p[2])
rnull = function(p=c(0,1)) rnorm(500, p[1], p[2])
ralt = function(df=1) {
  x=rt(5000, df)
  x=x[abs(x)<10]
  x[1:500]
}
phat = function(x) c(mean(x), sd(x))

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
                param_alt=1:25, phat=phat, maxProcessor=1, B=c(500, 500))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
a=nrow(pwr_cont)
par_cont_80=rbind(par_cont_80, "16: Normal  - t, estimated" = find.par(pwr_cont[a:1, ],0.8))
```

**Note** no check for type I error as null hypothesis is always false.

**Discrete**

```{r normal.t.est.disc}
bins = c(-2.5, seq(-2.5, 2.5, length=49), 2.5)
vals = (bins[-1]+bins[-51])/2

pnull = function(p=c(0,1)) {
  bins = c(seq(-2.5, 2.5, length=49), Inf)
  pnorm(bins, p[1], p[2])
}
rnull=function(p=c(0,1)) {
  bins = c(-Inf, seq(-2.5, 2.5, length=49), Inf)
  p=diff(pnorm(bins, p[1], p[2]))
  c(rmultinom(1, 500, p))
}
ralt=function(df=1) {
  bins = c(-Inf, seq(-2.5, 2.5, length=49), Inf)
  p=diff(pt(bins, df))
  c(rmultinom(1, 500, p))
}
phat = function(x) {
  bins = c(-2.5, seq(-2.5, 2.5, length=49), 2.5)
  vals = (bins[-1]+bins[-51])/2
  c(mean(rep(vals, x)), sd(rep(vals, x)))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, 
                    param_alt=1:25, phat)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
a=nrow(pwr_disc)
par_disc_80=rbind(par_disc_80, "16: Normal  - t, estimated" = find.par(pwr_disc[a:1,],0.8))
multiple.graphs(plot_power(pwr_cont, "df"), 
                plot_power(pwr_disc, "df"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

## Case Study 17: Exponential  -  Weibull, estimated

```{r}
ggcurve(function(x) dexp(x,1), 
        function(x) dweibull(x, 1.2, 1),
        xrange=c(0,6))
```


**Continuous**

```{r exponential.weibull.est.cont}
pnull = function(x, p=1) pexp(x, p)
qnull = function(x, p=1) qexp(x, p)
rnull = function(p=1) rexp(500, p)
ralt = function(b=1) rweibull(500, b, 1)
phat = function(x) 1/mean(x)

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
        param_alt=seq(1, 1.5, length=25), phat=phat, Range=c(0,Inf))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_05=rbind(par_cont_05, "17: Exponential - Weibull, estimated" = pwr_cont[1, ])
par_cont_80=rbind(par_cont_80, "17: Exponential - Weibull, estimated" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r exponential.weibull.est.disc}
bins=seq(0, 4, length=51)
vals=(bins[-1]+bins[-51])/2

pnull = function(a=1) {
  bins=seq(0, 4, length=51)
  pexp(c(bins[2:50],Inf), a)
}

rnull=function(a=1) {
  bins=seq(0, 4, length=51)
  p = diff(pexp(c(0, bins[2:50],Inf), a))
  c(rmultinom(1, 500, p))
}

ralt=function(b=1) {
  bins=seq(0, 4, length=51)
  p = diff(pweibull(c(0, bins[2:50], Inf), b, 1))
  c(rmultinom(1, 500, p))
}

phat = function(x) {
  bins=seq(0, 4, length=51)
  vals=(bins[-1]+bins[-51])/2
  1/mean(rep(vals, x))
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
              param_alt=seq(1, 1.5, length=25), phat)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_05=rbind(par_disc_05, "17: Exponential - Weibull, estimated" = pwr_disc[1, ])
par_disc_80=rbind(par_disc_80, "17: Exponential - Weibull, estimated" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```


## Case Study 18: Truncated Exponential  -  Linear, estimated

```{r}
ggcurve(function(x) dexp(x, 1)/diff(pexp(c(0, 1), 1)), 
        function(x) 2*(-0.4)*x+1-(-0.4))
```


**Continuous**

```{r trunc.exponential.linear.est.cont}
pnull = function(x, p=1) (1-exp(-x*p))/(1-exp(-p))
qnull = function(x, p=1) -log(1 - x*(1-exp(-p)))/p
rnull = function(p=1) {
    x = NULL
    repeat {
        x = c(x, rexp(1000, p))
        x = x[x < 1]
        if (length(x) > 1000) 
            break
    }
    x[1:1000]
}
ralt = function(slope) {
  if(slope==0) y=runif(1000)
    else y=(slope-1+sqrt((1-slope)^2+4*slope* runif(1000)))/2/slope
}
phat = function(x) {
    n = length(x)
    s = sum(x)
    p = n/s
    repeat {
        o = p
        t = exp(-o)
        l1 =  n/o - s - n*t/(1-t)
        l2 = (-n/o^2 + n * t/(1-t)^2)
        p = o - l1/l2
        if(p<0) return(0.001)
        if (abs(p - o) < 0.01) 
            break
    }
    p
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, 
      param_alt=seq(-0.5, -1, length=25), phat=phat, Range=c(0,1))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

**Discrete**

```{r trunc.exponential.linear.est.disc}
bins = 0:100/100
vals = (bins[-1]+bins[-101])/2

pnull = function(a=1) {
  bins=1:100/100
  (1-exp(-bins*a))/(1-exp(-a))
}
rnull=function(a=1) {
  bins=0:100/100
  p=diff(1-exp(-bins*a))
  c(rmultinom(1, 1000, p))
}

ralt = function(slope) {
    if(slope==0) p=rep(1/100, 100)
    else p=diff(slope * (0:100/100)^2 + (1 - slope) * 0:100/100)  
    c(rmultinom(1, 1000, p))
}

phat = function(x) {
    bins=0:100/100
    vals=(bins[-1]+bins[-101])/2
    n = sum(x)
    s = sum(vals*x)
    p = n/s
    repeat {
        o = p
        t = exp(-o)
        l1 =  n/o - s - n*t/(1-t)
        l2 = (-n/o^2 + n * t/(1-t)^2)
        p = o - l1/l2
        if(p<0) return(0.01)
        if (abs(p - o) < 0.01) 
            break
    }
    p
}
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt,
                      param_alt=seq(-0.5, -1, length=25), phat)
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_80=rbind(par_cont_80, "18: Trunc Exponential - Linear, estimated" = find.par(pwr_cont, 0.8))
par_disc_80=rbind(par_disc_80, "18: Trunc Exponential - Linear, estimated" = find.par(pwr_disc, 0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))

multiple.graphs(plot_power(pwr_cont, "slope"), 
                plot_power(pwr_disc, "slope"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```


## Case Study 19: Exponential  -  Gamma, estimated

```{r}
ggcurve(function(x) dexp(x,1), 
        function(x) dgamma(x, 1, 1.5),
        xrange=c(0,6))
```


**Continuous**

```{r exponential.gamma.est.cont}
pnull = function(x, p) pexp(x, p)
qnull = function(x, p) qexp(x, p)
rnull = function(p) rexp(500, p)
ralt = function(b=1) rgamma(500, b, 1)
phat = function(x) 1/mean(x)
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt, phat,
        param_alt=seq(1, 1.3, length=25), Range=c(0,Inf))
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_cont_80=rbind(par_cont_80, "19: Exponential - Gamma, estimated" = find.par(pwr_cont,0.8))
```

**Discrete**

```{r exponential.gamma.est.disc}
bins = seq(0, 4, length=51)
vals = (bins[-1]+bins[-51])/2
pnull = function(b=1) {
  bins = seq(0, 4, length=50)
  pexp(c(bins[-1], Inf), b)
}  
rnull=function(b=1) {
  bins = seq(0, 4, length=50)
  p=diff(pexp(c(bins, Inf), b))  
  c(rmultinom(1, 500, p))
}
ralt=function(b=1) {
  bins = seq(0, 4, length=50)
  p=diff(pgamma(c(bins, Inf), b, 1))
  c(rmultinom(1, 500, p))
}

phat=function(x) {
  bins = seq(0, 4, length=51)
  vals = (bins[-1]+bins[-51])/2
  1/mean(rep(vals, x))
}
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, phat, 
              param_alt=seq(1, 1.3, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
par_disc_80=rbind(par_disc_80, "19: Exponential - Gamma, estimated" = find.par(pwr_disc,0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```

**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

### Case 20: Normal - Cauchy (Breit Wigner) truncated to [-5,5], estimated

```{r normal.cauchy.est.cont}
pnull = function(x, s=1) pnorm(x, 0, s)
qnull = function(x, s=1) qnorm(x, 0, s)
rnull = function(s=1) rnorm(500, 0, s)
ralt = function(s) s*tan( (2*runif(500)-1)*atan(5/s))
phat = function(x) {
  ll=function(s, x) -sum(log(dnorm(x,0,s))-log(2*pnorm(5,0,s)-1))
  optimize(ll, c(0,20), x=x)$minimum
}

which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_cont=gof_power_cont(pnull, rnull, qnull, ralt,   param_alt=seq(1, 2,length=25), phat)
  write.table(pwr_cont, paste0("SimulationResults/", which, ".dat"))
} else pwr_cont=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```

```{r}
a=nrow(pwr_cont)
par_cont_80=rbind(par_cont_80, "20: Normal  - Cauchy, estimated" = find.par(pwr_cont[a:1, ],0.8))
```


```{r normal.cauchy.est.disc}
bins = seq(-5, 5, 0.25)
vals = (bins[-1]+bins[-41])/2
pnull = function(s=1) {
  bins = seq(-5, 5, 0.25)
  pnorm(bins[-1], 0, s)/(2*pnorm(5, 0, s)-1)
}  
rnull=function(s=1) {
  bins=seq(-5, 5, 0.25)
  p=diff(pnorm(bins, 0, s))
  c(rmultinom(1, 500, p))
}
ralt = function(s=1) {
  bins=seq(-5, 5, 0.25)
  p=diff(pcauchy(bins, 0, s))
  c(rmultinom(1, 500, p))
}  
phat = function(x) {
  ll=function(s, x) {
    bins = seq(-5, 5, 0.25)
    vals = (bins[-1]+bins[-41])/2    
    -sum(x*log(dnorm(vals,0,s)))+sum(x)*log(2*pnorm(5,0,s)-1)
  }  
  optimize(ll, c(0, 4), x=x)$minimum
}
which = knitr::opts_current$get()$label
if(which %in% whichTOrerun) {
  pwr_disc=gof_power_disc(pnull, rnull, vals, ralt, phat, 
              param_alt=seq(1, 2, length=25))
  write.table(pwr_disc, paste0("SimulationResults/", which, ".dat"))
} else pwr_disc=as.matrix(read.table(paste0("SimulationResults/", which,  ".dat")))
```


```{r}
a=nrow(pwr_disc)
par_disc_80=rbind(par_disc_80, "20: Normal - Cauchy, estimated" = find.par(pwr_disc[a:1, ], 0.8))
multiple.graphs(plot_power(pwr_cont, "b"), 
                plot_power(pwr_disc, "b"))
```


**Continuous - Discrete**

```{r}
comp.power(pwr_cont, pwr_disc)
```

```{r}
write.table(par_cont_80, "par_cont_80.txt")
write.table(par_disc_80, "par_disc_80.txt")
write.table(par_cont_05, "par_cont_05.txt")
write.table(par_disc_05, "par_disc_05.txt")
```


## Type I errors

**Continuous Data**

```{r}
round(par_cont_05[, 1:8]*100,1)
round(par_cont_05[, 9:17]*100,1)
```

**Discrete Data**

```{r}
round(par_disc_05[, 1:7]*100,1)
round(par_disc_05[, 8:12]*100,1)
```

As we can see, all the methods achieve the correct type I error rate of $5\%$, within simulation error. In the discrete case many have an actual type I error much smaller than $5\%$, as is often the case for discrete data.

Note that in  Case 9: Normal - t, Case 16: Normal - t, estimated, Case 15: Truncated Exponential - Linear and  Case 18: Truncated Exponential - Linear, estimated the null hypothesis is always wrong, and therefore no check of the type I error is possible.

## Power

The following table shows the powers of all the methods at that value of the parameter where at least one method has a power higher then $80\%$:

**Continuous Data**

```{r}
round(par_cont_80[, 1:7]*100,1)
round(par_cont_80[, 8:17]*100,1)
```

**Discrete Data**

```{r}
round(par_disc_80[, 1:7]*100,1)
round(par_disc_80[, 8:12]*100,1)
```

In all cases the powers differ widely, with no clear pattern of which methods are best. Any one method can perform very well in one case and very poorly in another.

In Case 18: Truncated Exponential - Linear, estimated the power is always quite small so this case is left out.

Of course these estimates are subject to simulation error. To get a clearer picture of the relative performance we proceed as follows. For each case a method is assigned a 1 if its power it at least $90\%$ of the power of the best method, and a 0 otherwise. Then we count how often a method is close to best.

**Continuous Data**


```{r}
par_cont_80_max=apply(par_cont_80, 1, max)
par_cont_80_index=0*par_cont_80
for(i in seq_along(par_cont_80_max))
  par_cont_80_index[i, ]=ifelse(par_cont_80[i, ]>0.9*par_cont_80_max[i], 1, 0)
sort(apply(par_cont_80_index, 2, sum))[17:1]
```

Chi-square with a large number of equal probability bins, either using Pearsons formula or the likelihood ratio, never has a power close to the best.  ZC is best 9 times, AD is best 8 times of the 20 case studies.

**Discrete Data**

```{r}
par_disc_80_max=apply(par_disc_80, 1, max)
par_disc_80_index=0*par_disc_80
for(i in seq_along(par_disc_80_max))
  par_disc_80_index[i, ]=ifelse(par_disc_80[i, ]>0.9*par_disc_80_max[i], 1, 0)
sort(apply(par_disc_80_index, 2, sum))[12:1]
```

Here AD is best, with 10 of the 20 discrete studies.

## Comparison of Chi Square Variants

```{r}
sort(round(100*sort(apply(par_cont_80[,10:17], 2, mean))))[8:1]
sort(round(100*sort(apply(par_cont_80[,10:17], 2, mean))))[8:1]
```

In general a small number of bins (10 in our studies) is better than a large one. Equal size bins are slightly better than equal probability bins. The difference between Pearson's formula and likelihood ratio test formula is negligible.  


## Best Default Selection

One can of course simply run all the methods on the two data sets. This, however will lead to a severe simultaneous testing problem. Therefore we want to find as small a selection of methods that nevertheless includes the best method (within simulation error) in each of the case studies included. 

The following routine checks all combinations of k methods to see whether they include at least one method that is within $90\%$ of the best. If so it also finds the mean power of this selection over all cases.

```{r}
best.combination=function(res, res_index, k) {
  N   <- ncol(res)
  vec <- c(FALSE, TRUE)
  lst <- lapply(numeric(N), function(x) vec)
  a=as.matrix(expand.grid(lst))
  I=a[apply(a,1,sum)==k,]
  A=NULL
  b=NULL
  for(i in 1:nrow(I)) {
     z=res_index[, I[i,]]
     if(min(apply(z,1,sum))==0) next
     A=rbind(A, colnames(z))
     b=c(b, mean(res[, I[i,]]))   
  }
  if(is.null(A)) return("No Selection")
  A=data.frame(A, "Mean Power"=round(b,3))
  A[order(b), ]
}
```


**Continuous Data**

We begin by considering all combinations of three methods:


```{r}
best.combination(par_cont_80, par_cont_80_index,5)
```

and we see that no collection of five method suffices.

```{r}
best_cont=best.combination(par_cont_80, par_cont_80_index,6)
best_cont
```

and so four selections of six methods work. W, ZK, ZC and Wassp1 appear in all of them. In addition one of the four chi square versions with a small number of bins is useful, either with equal size or equal probability bins. The one with the highest mean power is EP small Pearson, ES.small Pearson, W, Wasp1, ZK  and ZC, which therefore is our default selection. One other selections have essentially the same power (within simulation error) and could therefore also be used.

```{r}
write.table(best_cont, "best_cont.txt")
```

**Discrete Data**

Here we begin by considering all combinations of three methods:

```{r}
best.combination(par_disc_80, par_disc_80_index,3)
```

and we see that no collection of three methods suffices.

```{r}
best_disc=best.combination(par_disc_80, par_disc_80_index,4)
best_disc
```

and so ten selections of four methods work. AD is the only method in all these selections, ZC appears in 8 of the 10. The one with the highest mean power is Kuiper, AD, ZA and ZC, which therefore is our default selection. Note that there is no chi square test in this selection.

```{r}
write.table(best_disc, "best_disc.txt")
```


